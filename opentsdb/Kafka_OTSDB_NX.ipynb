{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--jars /home/jovyan/telemetry/spark-streaming-kafka-assembly_2.11-1.6.3.jar pyspark-shell'\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark import SparkContext\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.streaming.kafka import KafkaUtils\n",
    "from pyspark.sql.functions import explode\n",
    "from __future__ import print_function\n",
    "from pyspark.sql.types import *\n",
    "import requests\n",
    "import json\n",
    "import numbers\n",
    "import ast\n",
    "from collections import OrderedDict\n",
    "sc = SparkContext()\n",
    "ssc = StreamingContext(sc, 1)\n",
    "kafkaParams = {\"metadata.broker.list\": \"localhost:9092\", \"auto.offset.reset\": \"largest\"}\n",
    "topic = \"telemetrynx\"\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "kafkaStream = KafkaUtils.createDirectStream(ssc,[topic],kafkaParams)\n",
    "\n",
    "#kafka_rdd = kafkaStream.map(lambda (k,v): v)\n",
    "kafka_rdd = kafkaStream.map(lambda v: json.loads(v[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path1 = \"show interface counters\"\n",
    "path2 = \"show bgp all summary\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(rdd):\n",
    "    json_data = sqlContext.read.json(rdd)\n",
    "    # NX Data comes out weird, need to convert (Single Quotes instead of double quote issues)\n",
    "    data_broken = json_data.collect()[0].asDict()['_corrupt_record']\n",
    "    data = data_broken.replace(\"u'\", \"'\")\n",
    "    data = ast.literal_eval(data)\n",
    "    tags_master = {\n",
    "        'NodeID' : data['Telemetry']['node_id_str'],\n",
    "        'EncodingPath' : data['Telemetry']['encoding_path'].replace(\" \", \"-\")\n",
    "    }\n",
    "    for row in data[\"Rows\"]:\n",
    "        metrics = {\n",
    "            \"metric\": 'metric',\n",
    "            \"timestamp\": 'timestamp',\n",
    "            \"value\": 'value',\n",
    "            \"tags\": 'tags'}\n",
    "        content_keys_master = {}\n",
    "        content_keys = content_keys_master.copy()\n",
    "        tags = tags_master.copy()\n",
    "        metrics['timestamp'] = data[\"Telemetry\"]['msg_timestamp']/1000\n",
    "        content = row['Content']\n",
    "        tsdb =  []\n",
    "        if data['Telemetry']['encoding_path'] == path1:\n",
    "            interface_loader(metrics, content, 'rx', tags)\n",
    "            interface_loader(metrics, content, 'tx', tags)\n",
    "        if data['Telemetry']['encoding_path'] == path2:\n",
    "            result = bgp_loader(metrics, content, tags)\n",
    "            tsdb_api_put(result)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bgp_loader(metrics, content, tags):\n",
    "    tsdb = []\n",
    "    tags_copy = tags.copy()\n",
    "    keys = ['totalpaths', 'totalnetworks']\n",
    "    vrf = content['']['TABLE_vrf']['']['ROW_vrf']['']\n",
    "    bgp = vrf['TABLE_af']['']['ROW_af']['_PIPELINE_EDIT']\n",
    "    for saf in bgp:\n",
    "        bgp_info = saf['TABLE_saf']['']['ROW_saf']['']\n",
    "        for key in keys:\n",
    "            if key in bgp_info:\n",
    "                metrics_copy = metrics.copy()\n",
    "                metrics_copy['metric'] = key\n",
    "                metrics_copy['value'] = bgp_info[key]\n",
    "                metrics_copy['tags'] = tags_copy\n",
    "                tsdb.append(metrics_copy)\n",
    "    return json.loads(json.dumps(tsdb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interface_loader(metrics, content, way, tags):\n",
    "    tsdb = []\n",
    "    tags_copy = tags.copy()\n",
    "    segment = content['']['TABLE_{}_counters'.format(way)]['']['ROW_{}_counters'.format(way)]['_PIPELINE_EDIT']\n",
    "    for interface in segment:\n",
    "        tags_copy['interface_name'] = interface['interface_{}'.format(way)]\n",
    "        for key in interface.keys():\n",
    "            if isinstance(interface[key], numbers.Number):\n",
    "                metrics_copy = metrics.copy()\n",
    "                metrics_copy['metric'] = key\n",
    "                metrics_copy['value'] = interface[key]\n",
    "                metrics_copy['tags'] = tags_copy\n",
    "                tsdb_api_put(metrics_copy)\n",
    "    return\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def system_loader(metrics, content, tags):\n",
    "    tsdb = []\n",
    "    tags_copy = tags.copy()\n",
    "    segment = content['']\n",
    "    metrics_wanted = [\n",
    "        'cpu_state_idle',\n",
    "        'cpu_state_kernel',\n",
    "        'cpu_state_user',\n",
    "        'memory_usage_used',\n",
    "        'memory_usage_free',\n",
    "        'memory_usage_total']\n",
    "    for key in metrics_wanted:\n",
    "        metrics_copy = metrics.copy()\n",
    "        metrics_copy['metric'] = key\n",
    "        metrics_copy['value'] = segment[key]\n",
    "        metrics_copy['tags'] = tags_copy\n",
    "        tsdb.append(metrics_copy)\n",
    "    return json.loads(tsdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tsdb_api_put(data):\n",
    "    if data:\n",
    "        host = 'opentsdb:4242'\n",
    "        openTsdbUrl = 'http://' + host + '/api/put/details'\n",
    "        request = requests.post(openTsdbUrl, json = data)\n",
    "        if request.text:\n",
    "            print(request.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kafka_rdd.foreachRDD(lambda rdd: sc.parallelize(transform(rdd)))\n",
    "#kafka_rdd.pprint()\n",
    "ssc.start()\n",
    "#ssc.awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
